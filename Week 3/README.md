# **Welcome to Week 3 of Data DaVinci**

This week, we will explore the foundational concepts of **Neural Networks**, a cornerstone of modern machine learning and artificial intelligence. Neural networks are inspired by the human brain and are designed to recognize patterns in data. They have become a powerful tool for tackling complex problems such as image recognition, natural language processing, and more.

**Neural Networks**: A neural network consists of layers of interconnected nodes (neurons). Each connection has a weight, which is adjusted during training to minimize error. Neural networks learn by propagating input data forward and adjusting weights backward through a process known as backpropagation.

- **Input Layer**: The first layer, which receives the raw data.
- **Hidden Layers**: Intermediate layers where computations and feature extraction occur.
- **Output Layer**: Produces the final prediction or classification.

**Activation Functions**: Functions applied to neurons to introduce non-linearity, enabling the network to model complex relationships. Common activation functions include ReLU, Sigmoid, and Tanh.  
**Loss Function**: Measures the difference between predicted and actual values. Popular loss functions include Mean Squared Error (MSE) for regression and Cross-Entropy for classification.  
**Backpropagation**: The process of updating weights using the gradient of the loss function with respect to each weight.  
**Learning Rate**: Controls how much the weights are adjusted during training. Itâ€™s a crucial hyperparameter that affects convergence.  
[Here](./mnist.ipynb) is an example python notebook that demonstrates the following concepts.

This week has 2 assignments (archive.zip is to be used for the first assignment):

- [Simple Neural Network](./Neural-Networks.ipynb)
- [Convolution Neural Network](./CNN.ipynb)

Resources:

- [What are Neural Networks?](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)
- [Understanding Activation Functions](https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/)
- [Backpropagation Explained](https://www.youtube.com/watch?v=Ilg3gGewQ5U)
- [Batch Normalization](https://www.youtube.com/watch?v=tNIpEZLv_eg)
- [Dropout Explained](https://www.youtube.com/watch?v=ARq74QuavAo)
- [TensorFlow Basics](https://www.tensorflow.org/tutorials/quickstart/beginner)
